{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pathlib import Path \n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "from transformers import (\n",
    "    BertForTokenClassification, \n",
    "    BertTokenizerFast, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.cwd().parent\n",
    "data_dir = base_dir / 'data'\n",
    "\n",
    "dataset_name = 'resume_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Jha\\nApplication Development Associat...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n",
       "      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n",
       "      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Abhishek Jha\\nApplication Development Associat...   \n",
       "1  Afreen Jamadar\\nActive member of IIIT Committe...   \n",
       "2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n",
       "3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n",
       "4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n",
       "\n",
       "                                          annotation  extras  \n",
       "0  [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n",
       "1  [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n",
       "2  [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n",
       "3  [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n",
       "4  [{'label': ['Degree'], 'points': [{'start': 20...     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_json(data_dir / dataset_name, lines=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/singhsourabh/Resume-NER/blob/master/utils.py\n",
    "\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "\n",
    "def convert_goldparse(dataturks_JSON_FilePath):\n",
    "    \"\"\"\n",
    "    Converts labeled data from a Dataturks JSON file format into spaCy's NER training format.\n",
    "    \n",
    "    Args:\n",
    "        dataturks_JSON_FilePath (str): Path to the Dataturks JSON file containing the labeled data.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples representing spaCy-compatible training data in the format:\n",
    "              [\n",
    "                  (\n",
    "                      \"content\",\n",
    "                      {\n",
    "                          \"entities\": [(start, end, entity_label), ...]\n",
    "                      }\n",
    "                  ),\n",
    "                  ...\n",
    "              ]\n",
    "        or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        training_data = []\n",
    "        \n",
    "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)  \n",
    "            text = data['content'].replace(\"\\n\", \" \")  \n",
    "            entities = []  \n",
    "            data_annotations = data.get('annotation', None)\n",
    "            \n",
    "            if data_annotations:\n",
    "                for annotation in data_annotations:\n",
    "                    point = annotation['points'][0]  \n",
    "                    labels = annotation['label']\n",
    "\n",
    "                    if not isinstance(labels, list):\n",
    "                        labels = [labels]\n",
    "\n",
    "                    for label in labels:\n",
    "                        point_start = point['start']  # Start position of the entity\n",
    "                        point_end = point['end']      # End position of the entity\n",
    "                        point_text = point['text']    # Text covered by this entity\n",
    "\n",
    "                        # Calculate differences for leading/trailing whitespaces in the entity text\n",
    "                        lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
    "                        rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
    "                        \n",
    "                        # Adjust start and end indices to remove extra whitespaces\n",
    "                        if lstrip_diff != 0:\n",
    "                            point_start += lstrip_diff\n",
    "                        if rstrip_diff != 0:\n",
    "                            point_end -= rstrip_diff\n",
    "                        \n",
    "                        entities.append((point_start, point_end + 1, label))\n",
    "            \n",
    "            training_data.append((text, {\"entities\": entities}))\n",
    "        \n",
    "        return training_data\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
    "        return None\n",
    "\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"\n",
    "    Cleans spaCy-compatible training data by removing leading and trailing white spaces\n",
    "    from entity spans.\n",
    "    \n",
    "    Args:\n",
    "        data (list): The training data in spaCy format with each entry as a tuple:\n",
    "                     [\n",
    "                         (\n",
    "                             \"content\",\n",
    "                             {\n",
    "                                 \"entities\": [(start, end, label), ...]\n",
    "                             }\n",
    "                         ),\n",
    "                         ...\n",
    "                     ]\n",
    "    \n",
    "    Returns:\n",
    "        list: The cleaned training data with precise entity spans after removing whitespace.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to match whitespace characters\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "   \n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']  \n",
    "        valid_entities = []  \n",
    "\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start  # Initialize valid start position\n",
    "            valid_end = end      # Initialize valid end position\n",
    "\n",
    "            # Adjust valid_start to skip leading whitespace characters\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(text[valid_start]):\n",
    "                valid_start += 1\n",
    "            \n",
    "            # Adjust valid_end to skip trailing whitespace characters\n",
    "            while valid_end > 1 and invalid_span_tokens.match(text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            \n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = [\"UNKNOWN\", \"O\", \"Name\", \"Degree\", \"Skills\", \"College Name\", \"Email Address\",\n",
    "             \"Designation\", \"Companies worked at\", \"Graduation Year\", \"Years of Experience\", \"Location\"]\n",
    "\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "idx2tag = {i: t for i, t in enumerate(tags_vals)}\n",
    "\n",
    "def get_label(offset, labels):\n",
    "    if offset[0] == 0 and offset[1] == 0:\n",
    "        return 'O'\n",
    "    for label in labels:\n",
    "        if offset[1] >= label[0] and offset[0] <= label[1]:\n",
    "            return label[2]\n",
    "    return 'O'\n",
    "\n",
    "def process_resume(data, tokenizer, tag2idx, max_len, is_test=False):\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data[0], max_length=max_len, return_offsets_mapping=True)\n",
    "    curr_sent = {'orig_labels': [], 'labels': []}\n",
    "\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "\n",
    "    if not is_test:\n",
    "        labels = data[1]['entities']\n",
    "        labels.reverse()\n",
    "        for off in tok['offset_mapping']:\n",
    "            label = get_label(off, labels)\n",
    "            curr_sent['orig_labels'].append(label)\n",
    "            curr_sent['labels'].append(tag2idx[label])\n",
    "        curr_sent['labels'] = curr_sent['labels'] + ([0] * padding_length)\n",
    "\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent\n",
    "\n",
    "\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, resume, tokenizer, tag2idx, max_len, is_test=False):\n",
    "        self.resume = resume\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.tag2idx = tag2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.resume)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = process_resume(\n",
    "            self.resume[idx], self.tokenizer, self.tag2idx, self.max_len, self.is_test)\n",
    "        return {\n",
    "            'input_ids': torch.tensor(data['input_ids'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data['token_type_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(data['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(data['labels'], dtype=torch.long),\n",
    "            'orig_label': data['orig_labels']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = trim_entity_spans(convert_goldparse(data_dir / dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples : 187\n",
      "Number of Validation Samples : 33\n"
     ]
    }
   ],
   "source": [
    "TEST_SPLIT=0.15\n",
    "text = [_[0] for _ in cleaned_data]\n",
    "entities = [_[1] for _ in cleaned_data]\n",
    "\n",
    "train_text, valid_text, train_entities, valid_entities = train_test_split(text, \n",
    "                                                            entities, \n",
    "                                                            test_size=TEST_SPLIT, \n",
    "                                                            random_state=10\n",
    "                                                            )\n",
    "\n",
    "train_data = [(train_text[i], train_entities[i])   for i in range(len(train_text))]\n",
    "valid_data = [(valid_text[i], valid_entities[i])   for i in range(len(valid_text))]\n",
    "\n",
    "print(\"Number of Training Samples : {TRAIN_DATA}\".format(TRAIN_DATA=len(train_data)))\n",
    "print(\"Number of Validation Samples : {VALID_DATA}\".format(VALID_DATA=len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(base_model_name, truncation=True)\n",
    "model = BertForTokenClassification.from_pretrained(base_model_name, num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500  # Set based on your requirements\n",
    "\n",
    "train_dataset = ResumeDataset(train_data, tokenizer, tag2idx, max_len)\n",
    "val_dataset = ResumeDataset(valid_data, tokenizer, tag2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_tokens(tokenizer, tag2idx):\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    pad_tok = vocab[\"[PAD]\"]\n",
    "    sep_tok = vocab[\"[SEP]\"]\n",
    "    cls_tok = vocab[\"[CLS]\"]\n",
    "    o_lab = tag2idx[\"O\"]\n",
    "    return pad_tok, sep_tok, cls_tok, o_lab\n",
    "\n",
    "\n",
    "\n",
    "pad_tok, sep_tok, cls_tok, o_lab = get_special_tokens(tokenizer, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "\n",
    "    # Apply argmax to get the predicted class indices\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Initialize lists to store filtered predictions and true labels\n",
    "    valid_predictions, valid_labels = [], []\n",
    "\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        # Mask the predictions to exclude [CLS], [SEP], [PAD]\n",
    "        preds_mask = (label != pad_tok) & (label != sep_tok) & (label != cls_tok)\n",
    "\n",
    "        # Apply the mask to the predictions only\n",
    "        valid_pred = np.array(pred)[preds_mask]\n",
    "        valid_label = np.array(label)[preds_mask]\n",
    "\n",
    "        # Convert to tag names using idx2tag mapping\n",
    "        valid_predictions.append([idx2tag[p] for p in valid_pred])\n",
    "        valid_labels.append([idx2tag[l] for l in valid_label])\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(valid_labels, valid_predictions)\n",
    "    recall = recall_score(valid_labels, valid_predictions)\n",
    "    f1 = f1_score(valid_labels, valid_predictions)\n",
    "    accuracy = accuracy_score(valid_labels, valid_predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ner_exp1'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=base_dir / f\"checkpoints/{experiment_name}\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=10_000,\n",
    "    logging_dir= base_dir / f\"checkpoints/{experiment_name}/logs\",\n",
    "    logging_steps=200,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.364806</td>\n",
       "      <td>0.618047</td>\n",
       "      <td>0.549149</td>\n",
       "      <td>0.581564</td>\n",
       "      <td>0.890943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304992</td>\n",
       "      <td>0.671306</td>\n",
       "      <td>0.555373</td>\n",
       "      <td>0.607861</td>\n",
       "      <td>0.903156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293687</td>\n",
       "      <td>0.632105</td>\n",
       "      <td>0.659528</td>\n",
       "      <td>0.645525</td>\n",
       "      <td>0.900251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279549</td>\n",
       "      <td>0.713220</td>\n",
       "      <td>0.576754</td>\n",
       "      <td>0.637769</td>\n",
       "      <td>0.909163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285981</td>\n",
       "      <td>0.647279</td>\n",
       "      <td>0.666118</td>\n",
       "      <td>0.656563</td>\n",
       "      <td>0.906852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266024</td>\n",
       "      <td>0.674265</td>\n",
       "      <td>0.616228</td>\n",
       "      <td>0.643942</td>\n",
       "      <td>0.908173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254174</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.623833</td>\n",
       "      <td>0.657979</td>\n",
       "      <td>0.912266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248865</td>\n",
       "      <td>0.665811</td>\n",
       "      <td>0.711075</td>\n",
       "      <td>0.687699</td>\n",
       "      <td>0.912662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249045</td>\n",
       "      <td>0.681084</td>\n",
       "      <td>0.717738</td>\n",
       "      <td>0.698930</td>\n",
       "      <td>0.914906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>0.698465</td>\n",
       "      <td>0.694089</td>\n",
       "      <td>0.914708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=0.22910205523173013, metrics={'train_runtime': 37.5013, 'train_samples_per_second': 49.865, 'train_steps_per_second': 0.8, 'total_flos': 477215929080000.0, 'train_loss': 0.22910205523173013, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 10. Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/nfs/home/scg1143/ATSChecker/ner-extraction/checkpoints/final_model/tokenizer_config.json',\n",
       " '/nfs/home/scg1143/ATSChecker/ner-extraction/checkpoints/final_model/special_tokens_map.json',\n",
       " '/nfs/home/scg1143/ATSChecker/ner-extraction/checkpoints/final_model/vocab.txt',\n",
       " '/nfs/home/scg1143/ATSChecker/ner-extraction/checkpoints/final_model/added_tokens.json',\n",
       " '/nfs/home/scg1143/ATSChecker/ner-extraction/checkpoints/final_model/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(base_dir / f\"checkpoints/final_model\")\n",
    "tokenizer.save_pretrained(base_dir / f\"checkpoints/final_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.ner_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc5dcff28870a78261c6058eed80c552ebd7953d5071591ed305fed95c81e49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
